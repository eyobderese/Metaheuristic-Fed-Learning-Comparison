{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Environment Setup and Data Preparation\n\nThe first step simulates a realistic federated environment. We use a **pathological Non-IID split** of the MNIST dataset, where each of the 100 clients is assigned samples from only **2 class labels**. This creates the data heterogeneity necessary to test the robustness of the FedProx algorithm.\n\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nimport numpy as np\nimport copy\nimport matplotlib.pyplot as plt\nfrom scipy.stats import wilcoxon\n\n# Set seed for reproducibility\ntorch.manual_seed(42)\nnp.random.seed(42)\n\ndef get_mnist_non_iid(num_clients=100):\n    \"\"\"\n    Partitions MNIST into 100 Non-IID clients.\n    Each client receives data from exactly 2 classes.\n    \"\"\"\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n    ])\n    \n    train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)\n    \n    # Sort data by labels to create Non-IID shards\n    indices = np.arange(len(train_dataset))\n    labels = train_dataset.targets.numpy()\n    indices_sorted = indices[np.argsort(labels)]\n    \n    # Divide into 200 shards (each client gets 2 shards)\n    shards = np.split(indices_sorted, 200)\n    np.random.shuffle(shards)\n    \n    client_indices = {i: np.concatenate((shards[2*i], shards[2*i+1]), axis=0) \n                      for i in range(num_clients)}\n    \n    return train_dataset, test_dataset, client_indices\n\n# Initialize Data\ntrain_data, test_data, client_map = get_mnist_non_iid()\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Model Architecture\n\nWe implement a 2-layer **Multi-Layer Perceptron (MLP)**. This lightweight model is standard for benchmarking FL algorithms on MNIST and ensures fast convergence during your one-week experiment.\n\n","metadata":{}},{"cell_type":"code","source":"\nclass FederatedMLP(nn.Module):\n    def __init__(self):\n        super(FederatedMLP, self).__init__()\n        self.fc1 = nn.Linear(28 * 28, 200)\n        self.fc2 = nn.Linear(200, 100)\n        self.fc3 = nn.Linear(100, 10)\n\n    def forward(self, x):\n        x = x.view(-1, 28 * 28)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        return self.fc3(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. FedProx Local Training & Global Evaluation\n\nThe **FedProx** baseline introduces a **proximal term** () to the local loss function. This regularization term penalizes local updates that deviate significantly from the global model, stabilizing training on heterogeneous data.\n","metadata":{}},{"cell_type":"code","source":"def evaluate(model, loader):\n    model.eval()\n    correct = 0\n    with torch.no_grad():\n        for data, target in loader:\n            output = model(data)\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(target.view_as(pred)).sum().item()\n    return 100. * correct / len(loader.dataset)\n\ndef local_train_fedprox(model, global_model, train_loader, mu=0.01, epochs=1):\n    model.train()\n    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n    \n    for _ in range(epochs):\n        for data, target in train_loader:\n            optimizer.zero_grad()\n            output = model(data)\n            \n            # Standard Cross Entropy Loss\n            ce_loss = F.cross_entropy(output, target)\n            \n            # FedProx Proximal Term\n            prox_term = 0.0\n            for p, g_p in zip(model.parameters(), global_model.parameters()):\n                prox_term += (p - g_p).norm(2)**2\n            \n            loss = ce_loss + (mu / 2) * prox_term\n            loss.backward()\n            optimizer.step()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 4. Federated Orchestration (Baseline)\n\nThis loop coordinates the global communication rounds. Currently, it uses a **random selection** strategy, which serves as the SOTA baseline for comparison.\n\n","metadata":{}},{"cell_type":"code","source":"def run_federated_experiment(strategy_name=\"FedProx_Baseline\", num_rounds=30, clients_per_round=10):\n    global_model = FederatedMLP()\n    accuracy_history = []\n    \n    print(f\"Starting Experiment: {strategy_name}\")\n    \n    for r in range(num_rounds):\n        # 1. CLIENT SELECTION STEP \n        # (This is where you will plug in GA, PSO, or SA later)\n        all_ids = list(client_map.keys())\n        selected_ids = np.random.choice(all_ids, clients_per_round, replace=False)\n        \n        local_states = []\n        \n        # 2. LOCAL UPDATES\n        for cid in selected_ids:\n            local_model = copy.deepcopy(global_model)\n            indices = client_map[cid]\n            loader = torch.utils.data.DataLoader(train_data, batch_size=32, \n                                                 sampler=torch.utils.data.SubsetRandomSampler(indices))\n            \n            local_train_fedprox(local_model, global_model, loader, mu=0.01)\n            local_states.append(local_model.state_dict())\n            \n        # 3. GLOBAL AGGREGATION (Weighted Averaging)\n        global_dict = global_model.state_dict()\n        for key in global_dict.keys():\n            global_dict[key] = torch.stack([local_states[i][key] for i in range(len(local_states))], dim=0).mean(0)\n        global_model.load_state_dict(global_dict)\n        \n        # 4. SERVER EVALUATION\n        acc = evaluate(global_model, test_loader)\n        accuracy_history.append(acc)\n        if (r+1) % 5 == 0:\n            print(f\"Round {r+1}: Global Accuracy = {acc:.2f}%\")\n            \n    return accuracy_history\n\n# Run Baseline\nfedprox_results = run_federated_experiment(\"FedProx_Baseline\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 5. Visualization and Statistical Analysis\n\nFollowing section V of your guidelines, we provide the **Convergence Curve** and the **Wilcoxon rank-sum test** boilerplate.\n\n\n","metadata":{}},{"cell_type":"code","source":"\ndef plot_results(results_dict):\n    plt.figure(figsize=(10, 6))\n    for label, history in results_dict.items():\n        plt.plot(history, label=label)\n    plt.xlabel(\"Communication Rounds\")\n    plt.ylabel(\"Test Accuracy (%)\")\n    plt.title(\"Convergence Curves: SOTA vs Nature-Inspired Heuristics\")\n    plt.legend()\n    plt.grid(True)\n    plt.show()\n\n# Boilerplate for Wilcoxon Test (Compare Baseline vs your eventual GA/PSO/SA)\n# res = wilcoxon(fedprox_results, nia_results)\n# print(f\"P-value: {res.pvalue}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n\n\n### Integration Guide for NIA Step\n\nTo implement your **Genetic Algorithm**, **PSO**, or **SA**, you simply need to rewrite the \"Client Selection Step\" in Section 4.\n\n1. **Fitness Function:** Use the global accuracy (or a proxy like validation loss) as the fitness value for a particular subset of clients.\n2. **Search Space:** A binary string of length 100 (where '1' means a client is selected for that round).\n\nWould you like me to create the specific **Fitness Function interface** for your metaheuristics now?","metadata":{}}]}